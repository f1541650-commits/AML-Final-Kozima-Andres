# ğŸ“ Capstone Project: PredicciÃ³n de Abandono de Clientes en Telecomunicaciones

## ğŸ“‹ DescripciÃ³n del Proyecto

Sistema predictivo avanzado para identificar clientes con alto riesgo de abandono en la industria de telecomunicaciones usando arquitecturas de Deep Learning (MLP, LSTM, Transformer).

**Programa:** TEC-VIII - EspecializaciÃ³n en Big Data Analytics aplicada a los Negocios

---

## ğŸ¯ Objetivos

- Desarrollar modelos de Deep Learning para predecir churn con AUC-ROC â‰¥ 0.85
- Identificar factores crÃ­ticos de abandono usando SHAP values
- Segmentar clientes por nivel de riesgo para intervenciones dirigidas
- Demostrar ROI positivo (target: 300%+)

---

## ğŸ“Š Resultados Principales

| Modelo | AUC-ROC | F1-Score | Precision | Recall |
|--------|---------|----------|-----------|--------|
| **Transformer** | **0.91** | **0.87** | **0.85** | **0.89** |
| LSTM | 0.88 | 0.85 | 0.83 | 0.87 |
| MLP | 0.87 | 0.84 | 0.82 | 0.86 |

**Impacto de Negocio:**
- ğŸ’° ROI proyectado: **308%** en aÃ±o 1
- ğŸ’µ Beneficio neto: **$2.3M USD** anuales
- ğŸ“‰ ReducciÃ³n de churn: **18-22%**

---

## ğŸ—‚ï¸ Estructura del Repositorio
```
â”œâ”€â”€ notebooks/          # Notebook principal del proyecto
â”œâ”€â”€ src/               # CÃ³digo modular (modelos, preprocesamiento)
â”œâ”€â”€ data/              # Instrucciones para obtener el dataset
â”œâ”€â”€ results/           # MÃ©tricas y resultados
â”œâ”€â”€ figures/           # GrÃ¡ficos y visualizaciones
â”œâ”€â”€ report/            # Reporte final en PDF
â””â”€â”€ requirements.txt   # Dependencias del proyecto
```

---

## ğŸš€ CÃ³mo Ejecutar

### **OpciÃ³n 1: Google Colab (Recomendado)**

1. Abre el notebook en Colab:
   [![Open In Colab]((https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/f1541650-commits/capstone-churn-prediction/blob/main/notebooks/final_project.ipynb)

2. Activa GPU: `Runtime` â†’ `Change runtime type` â†’ `GPU`

3. Ejecuta todas las celdas: `Runtime` â†’ `Run all`

```

---

## ğŸ“¦ Dataset

**Fuente:** IBM Watson Analytics - Telco Customer Churn

El dataset se descarga automÃ¡ticamente desde:
```
https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv
```

**CaracterÃ­sticas:**
- 7,043 clientes
- 21 variables (demogrÃ¡ficas, servicios, cuenta)
- Variable objetivo: Churn (SÃ­/No)

Ver `data/README.md` para mÃ¡s detalles.

---

## ğŸ§  Modelos Implementados

### **1. Multi-Layer Perceptron (MLP)**
- Arquitectura: [256, 128, 64]
- BatchNormalization + Dropout (0.3)
- LeakyReLU activation

### **2. LSTM Bidireccional**
- Hidden size: 128, Layers: 2
- Attention mechanism
- Dropout regularization

### **3. Transformer (Mejor Performance)**
- Multi-head attention (8 heads)
- d_model: 128, Layers: 3
- Positional encoding learnable
- **AUC-ROC: 0.91** â­

---

## ğŸ“ˆ Factores CrÃ­ticos de Churn

SegÃºn anÃ¡lisis SHAP:

1. **Tipo de Contrato** (month-to-month = 3.2x riesgo)
2. **Tenure** (< 6 meses = 4.5x riesgo)
3. **Soporte TÃ©cnico** (ausencia = 2.1x riesgo)
4. **MÃ©todo de Pago** (electronic check = +38% churn)
5. **Total Charges** (inversamente correlacionado)

---

## ğŸ’¼ Recomendaciones de Negocio

### Corto Plazo (1-3 meses)
- Deploy modelo en producciÃ³n
- Programa de intervenciÃ³n para clientes <6 meses
- Ofrecer tech support gratuito a segmento alto riesgo

### Mediano Plazo (3-6 meses)
- Migrar contratos month-to-month a anuales
- Programa de retenciÃ³n personalizada por segmento
- Optimizar onboarding de 90 dÃ­as

### Largo Plazo (6-12 meses)
- Incentivar cambio a auto-pay (descuento 5%)
- Implementar CLV predictivo
- IntegraciÃ³n real-time con CRM

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Deep Learning:** PyTorch, TensorFlow/Keras
- **ML Tradicional:** scikit-learn, imbalanced-learn
- **Interpretabilidad:** SHAP, feature importance
- **VisualizaciÃ³n:** Matplotlib, Seaborn, Plotly
- **OptimizaciÃ³n:** Optuna

---

## ğŸ“„ Licencia

Este proyecto es material educativo para el programa TEC-VIII.

---

## ğŸ‘¤ Autor

** Andres Zyun Kozima Takashima**
- Email: zakt_91@hotmail.com
- GitHub: [@f1541650-commits](https://github.com/f1541650-commits)

---

## ğŸ“š Referencias

1. Vaswani et al. (2017). "Attention Is All You Need." NeurIPS.
2. Hochreiter & Schmidhuber (1997). "Long Short-Term Memory." Neural Computation.
3. Chawla et al. (2002). "SMOTE: Synthetic Minority Over-sampling Technique." JAIR.
4. IBM Watson Analytics. "Telco Customer Churn Dataset."

---

**Ãšltima actualizaciÃ³n:** Febrero 2026
