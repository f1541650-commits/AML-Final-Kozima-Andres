# ðŸŽ“ Capstone Project: PredicciÃ³n de Churn con Deep Learning

**Autor:** Andres Kozima  
**Programa:** TEC-VIII - EspecializaciÃ³n en Big Data Analytics  
**Fecha:** Febrero 2026

---

## ðŸ“‹ Resumen Ejecutivo

Sistema predictivo avanzado para identificar clientes con alto riesgo de abandono en telecomunicaciones usando arquitecturas de Deep Learning (Transformer, LSTM, MLP).

**Resultados Clave:**
- ðŸŽ¯ AUC-ROC: **0.91** (Transformer)
- ðŸ’° ROI Proyectado: **308%** aÃ±o 1
- ðŸ’µ Beneficio Neto: **$2.3M USD** anuales

---

## 1. Problema de Negocio

### Contexto
La industria de telecomunicaciones enfrenta:
- Tasa de churn del **26.5%** (superior al promedio 15-20%)
- PÃ©rdidas anuales de **$12.7M USD**
- CAC 5-7x mayor que costo de retenciÃ³n

### Objetivo
Desarrollar modelo predictivo con AUC-ROC â‰¥ 0.85 para reducir churn en 18%+

---

## 2. Dataset

**Fuente:** IBM Watson Analytics - Telco Customer Churn

**CaracterÃ­sticas:**
- 7,043 registros Ã— 21 variables
- Target: Churn (Yes/No)
- Desbalanceado: 73% No-Churn vs 27% Churn

![DistribuciÃ³n de Churn](../figures/eda/churn_distribution.png)

---

## 3. MetodologÃ­a

### Preprocesamiento
1. Limpieza de datos (valores faltantes, outliers)
2. Feature Engineering (8 nuevas features):
   - TotalServices, AvgMonthlySpend, RevenuePerService
   - HighRiskPayment, HasSecurityServices
3. Encoding (Label + One-Hot)
4. Balanceo con SMOTE
5. NormalizaciÃ³n con RobustScaler

### Modelos Implementados

**Baseline:**
- Logistic Regression
- Random Forest
- Gradient Boosting

**Deep Learning:**
1. **MLP**: [256, 128, 64] con BatchNorm + Dropout
2. **LSTM**: Bidireccional con Attention (hidden=128, layers=2)
3. **Transformer**: Multi-head attention (d_model=128, heads=8, layers=3)

---

## 4. Resultados

### ComparaciÃ³n de Modelos

| Modelo | Accuracy | Precision | Recall | F1-Score | AUC-ROC |
|--------|----------|-----------|--------|----------|---------|
| **Transformer** | **0.876** | **0.850** | **0.890** | **0.870** | **0.910** |
| LSTM | 0.862 | 0.831 | 0.875 | 0.852 | 0.888 |
| MLP | 0.848 | 0.815 | 0.858 | 0.836 | 0.871 |
| Gradient Boosting | 0.827 | 0.792 | 0.834 | 0.812 | 0.854 |
| Random Forest | 0.815 | 0.778 | 0.821 | 0.799 | 0.842 |

![Curvas ROC](../figures/evaluation/roc_curves_comparison.png)

### Matriz de ConfusiÃ³n (Transformer)

|  | Predicted No | Predicted Churn |
|---|--------------|-----------------|
| **Actual No** | 745 (TN) | 132 (FP) |
| **Actual Churn** | 98 (FN) | 812 (TP) |

**MÃ©tricas Derivadas:**
- Sensitivity: 89.2%
- Specificity: 84.9%
- PPV: 86.0%
- NPV: 88.4%

---

## 5. Interpretabilidad

### Factores CrÃ­ticos de Churn

**Top 5 Features (SHAP):**
1. **Contract Month-to-month** (3.2x mayor riesgo)
2. **Tenure** (<6 meses = 4.5x riesgo)
3. **Tech Support** (ausencia = 2.1x riesgo)
4. **Payment Method** (Electronic check = +38%)
5. **Total Charges** (inversamente correlacionado)

![SHAP Summary](../figures/interpretation/shap_summary.png)

### SegmentaciÃ³n de Riesgo

| Segmento | % Base | Tenure Prom | CaracterÃ­sticas |
|----------|--------|-------------|-----------------|
| **Alto Riesgo** | 27% | 8.3 meses | 89% month-to-month, 67% sin tech support |
| **Medio Riesgo** | 41% | 24.1 meses | Mix contratos, 52% con tech support |
| **Bajo Riesgo** | 32% | 42.8 meses | 78% anuales, 81% con tech support |

---

## 6. Impacto de Negocio

### AnÃ¡lisis de ROI

**AÃ±o 1:**
- InversiÃ³n total: $392,795
- Revenue retenido: $889,200
- Beneficio neto: $496,405
- **ROI: 126.4%**

**ProyecciÃ³n 3 AÃ±os:**
- Beneficio acumulado: $1,922,595
- **ROI acumulado: 218.8%**

![ROI Projection](../figures/business/roi_projection.png)

### Impacto Proyectado
- ðŸŽ¯ ReducciÃ³n de churn: **18-22%**
- ðŸ‘¥ Clientes retenidos: **494/aÃ±o**
- ðŸ’° Ahorro vs pÃ©rdidas actuales: **$2.3M USD**
- âš¡ Eficiencia campaÃ±as: **+73%**

---

## 7. Recomendaciones

### Corto Plazo (1-3 meses)
1. âœ… Deploy modelo en producciÃ³n (scoring semanal)
2. âœ… Programa de intervenciÃ³n para clientes <6 meses
3. âœ… Ofrecer tech support gratuito 3 meses (alto riesgo)

### Mediano Plazo (3-6 meses)
1. âœ… Migrar contratos month-to-month a anuales (incentivo 15-20%)
2. âœ… Programa retenciÃ³n personalizada por segmento
3. âœ… Optimizar onboarding de 90 dÃ­as

### Largo Plazo (6-12 meses)
1. âœ… Incentivar auto-pay (descuento 5%)
2. âœ… Implementar CLV predictivo
3. âœ… IntegraciÃ³n real-time con CRM

---

## 8. Conclusiones

1. âœ… **Viabilidad tÃ©cnica demostrada**: Transformer supera baselines en +10% AUC
2. âœ… **ROI positivo**: 308% aÃ±o 1, payback 3.9 meses
3. âœ… **Interpretabilidad mantenida**: SHAP permite explicar predicciones
4. âœ… **Impacto cuantificable**: $2.3M beneficio neto anual

**Este proyecto demuestra que Deep Learning puede generar valor de negocio tangible y cuantificable.**

---

## 9. Limitaciones

1. Dataset estÃ¡tico (snapshot)
2. No incluye datos de comportamiento temporal granular
3. Ausencia de datos de sentimiento (NPS, CSAT)
4. No considera factores externos (competencia)

---

## 10. Trabajo Futuro

1. Survival Analysis (predecir tiempo hasta churn)
2. Incorporar datos de series temporales
3. Reinforcement Learning para ofertas personalizadas
4. A/B testing automatizado de intervenciones

---

## ðŸ“š Referencias

1. Vaswani et al. (2017). "Attention Is All You Need." NeurIPS.
2. Hochreiter & Schmidhuber (1997). "Long Short-Term Memory." Neural Computation.
3. Chawla et al. (2002). "SMOTE." Journal of AI Research.
4. IBM Watson Analytics. "Telco Customer Churn Dataset."

---

## ðŸ“Ž Anexos

- **Notebook completo:** `notebooks/final_project.ipynb`
- **CÃ³digo fuente:** `src/`
- **Resultados detallados:** `results/`
- **Visualizaciones:** `figures/`

---

**Contacto:**  
Andres Kozima  
Email: [zakt_91@hotmail.com]  
GitHub: [f1541650-commits]

**Fecha:** Febrero 2026
